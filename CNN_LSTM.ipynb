{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ben-velastegui/dxc-ai-assessment/blob/main/CNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCdaGqQBfQUd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Conv1D, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPSzJPSydq15",
        "outputId": "7f7d4313-4929-47a1-e684-a98a21693fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Core libraries\n",
        "\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Feature importance\n",
        "!pip install shap\n",
        "import shap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_tZr3bceL1a"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/full_data_long.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GHIVW2YeWt-"
      },
      "outputs": [],
      "source": [
        "numeric_features = [\n",
        "    \"total_logs\", \"error_logs\", \"warning_logs\", \"info_logs\",\n",
        "    \"cpu_user_mean\", \"cpu_user_max\",\n",
        "    \"mem_used_mean\", \"mem_used_max\",\n",
        "    \"load1_mean\", \"load5_mean\", \"load15_mean\",\n",
        "    \"total_traces\", \"missing_data\"\n",
        "]\n",
        "\n",
        "\n",
        "categorical_features = [\"Hostname\", \"program\", \"pid\", \"user_id\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_29mHiofe1XM"
      },
      "outputs": [],
      "source": [
        "target = \"operation\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55MspEJ0e3eC"
      },
      "outputs": [],
      "source": [
        "time_column = \"bin_time\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXcl4foXe_Am"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "df[numeric_features] = scaler.fit_transform(df[numeric_features])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUnH72L2fB11"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Corrected for newer scikit-learn\n",
        "ohe = OneHotEncoder(sparse_output=False)\n",
        "cat_encoded = ohe.fit_transform(df[categorical_features])\n",
        "\n",
        "# Combine numeric + categorical features\n",
        "df_encoded = pd.concat([\n",
        "    df[numeric_features].reset_index(drop=True),\n",
        "    pd.DataFrame(cat_encoded, columns=ohe.get_feature_names_out(categorical_features))\n",
        "], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CAEZKqTfJr6"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df[\"operation_label\"] = label_encoder.fit_transform(df[target])\n",
        "y = to_categorical(df[\"operation_label\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWiFkw-0jesU",
        "outputId": "40880568-509b-47f7-c848-043d59cb7105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0   2019-11-19 17:38:00\n",
            "1   2019-11-19 17:38:00\n",
            "2   2019-11-19 17:38:00\n",
            "3   2019-11-19 17:38:00\n",
            "4   2019-11-19 17:38:00\n",
            "Name: bin_time, dtype: datetime64[ns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-32759934.py:2: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  df[\"bin_time\"] = pd.to_datetime(df[\"bin_time\"], errors=\"coerce\", infer_datetime_format=True)\n"
          ]
        }
      ],
      "source": [
        "# Convert bin_time to datetime, filling missing time as 00:00:00\n",
        "df[\"bin_time\"] = pd.to_datetime(df[\"bin_time\"], errors=\"coerce\", infer_datetime_format=True)\n",
        "\n",
        "# For entries that were just dates, pandas will automatically set time to 00:00:00\n",
        "# Verify\n",
        "print(df[\"bin_time\"].head())\n",
        "\n",
        "# Sort by Hostname and bin_time\n",
        "df = df.sort_values(by=[\"Hostname\", \"bin_time\"]).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLA-ZnMHkqL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37017be0-31dd-46da-b57c-d982644a1991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequences shape: (54783, 10, 189)\n",
            "Labels shape: (54783, 4)\n"
          ]
        }
      ],
      "source": [
        "sequence_length = 10  # number of time steps per sequence\n",
        "\n",
        "X_sequences = []\n",
        "y_sequences = []\n",
        "\n",
        "for host in df[\"Hostname\"].unique():\n",
        "    host_data = df[df[\"Hostname\"] == host]\n",
        "    host_features = df_encoded.loc[host_data.index].values\n",
        "    host_labels = df.loc[host_data.index, \"operation_label\"].values\n",
        "\n",
        "    for i in range(len(host_features) - sequence_length + 1):\n",
        "        X_sequences.append(host_features[i:i+sequence_length])\n",
        "        y_sequences.append(host_labels[i+sequence_length-1])  # label at last timestep\n",
        "\n",
        "X_sequences = np.array(X_sequences)\n",
        "y_sequences = np.array(y_sequences)\n",
        "y_sequences_cat = to_categorical(y_sequences)\n",
        "\n",
        "print(\"Sequences shape:\", X_sequences.shape)\n",
        "print(\"Labels shape:\", y_sequences_cat.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2qIyR0OksKi",
        "outputId": "5ba4a4f8-8d06-4515-cf0e-5e1d231f17bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (43826, 10, 189) (43826, 4)\n",
            "Test shape: (10957, 10, 189) (10957, 4)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_sequences, y_sequences_cat, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Test shape:\", X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "4-c8ymgMkupp",
        "outputId": "aae5250d-4198-4b2a-f5d6-72a27375814b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m189\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m36,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m6,176\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m20,544\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,716\u001b[0m (248.89 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,716</span> (248.89 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,524\u001b[0m (248.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,524</span> (248.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "input_shape = X_train.shape[1:]  # (sequence_length, num_features)\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "x = Conv1D(64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv1D(32, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(y_sequences_cat.shape[1], activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMHbnvM_kyHy",
        "outputId": "54d0c0b7-88b9-44ed-99c5-db793f0f3a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 14ms/step - accuracy: 0.6917 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 2/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.6926 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 3/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6909 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 4/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6947 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 5/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6927 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 6/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6881 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 7/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6892 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 8/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.6945 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 9/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6932 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 10/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6939 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 11/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6948 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 12/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6904 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 13/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6907 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 14/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 15ms/step - accuracy: 0.6942 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 15/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6935 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 16/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6930 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 17/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6906 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 18/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6924 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 19/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.6937 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 20/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.6894 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=20,\n",
        "    batch_size=32\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e86K0Iy_l7nG"
      },
      "outputs": [],
      "source": [
        "# Make sure operation column is clean before encoding\n",
        "df[target] = df[target].astype(str)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"operation_label\"] = label_encoder.fit_transform(df[target])\n",
        "y = to_categorical(df[\"operation_label\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3B2ude1muYA",
        "outputId": "d3982a8e-5a87-4f3d-cc2c-b5ff735dcbfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['boot_delete' 'image_create_delete' 'network_create_delete' 'unknown']\n"
          ]
        }
      ],
      "source": [
        "# Replace np.nan or string \"nan\" with \"unknown\"\n",
        "df[target] = df[target].replace(\"nan\", np.nan)  # catch string nan\n",
        "df[target] = df[target].fillna(\"unknown\").astype(str)\n",
        "\n",
        "# Refit label encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"operation_label\"] = label_encoder.fit_transform(df[target])\n",
        "y = to_categorical(df[\"operation_label\"])\n",
        "\n",
        "print(\"Classes:\", label_encoder.classes_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M0lEofgnAI5",
        "outputId": "1983f8e0-8062-4d80-b4ed-252c1689dcd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(0.361538258644792), 1: np.float64(3.1539346525540726), 2: np.float64(2.5187431091510475), 3: np.float64(1.9232496141433983)}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Use integer labels, not one-hot\n",
        "class_weights_array = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(df[\"operation_label\"]),\n",
        "    y=df[\"operation_label\"]\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights_array))\n",
        "\n",
        "print(\"Class weights:\", class_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MGP6ns-nD1B",
        "outputId": "bf69765c-8c76-4c59-9f62-62c7a676b4e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.6936 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 2/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.6917 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 3/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6918 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 4/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6932 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 5/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6930 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 6/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6944 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 7/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6915 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 8/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6960 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 9/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6888 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 10/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.6912 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 11/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6953 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 12/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6912 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 13/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.6908 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 14/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.6934 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 15/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6926 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 16/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6875 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 17/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6982 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 18/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.6906 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 19/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - accuracy: 0.6905 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 20/20\n",
            "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.6933 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6lveMML1n6Ux",
        "outputId": "8fd2fde2-9db8-475e-d80a-5eefdf0a0495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       precision    recall  f1-score   support\n",
            "\n",
            "          boot_delete       0.69      1.00      0.82      7565\n",
            "  image_create_delete       0.00      0.00      0.00       898\n",
            "network_create_delete       0.00      0.00      0.00      1060\n",
            "              unknown       0.00      0.00      0.00      1434\n",
            "\n",
            "             accuracy                           0.69     10957\n",
            "            macro avg       0.17      0.25      0.20     10957\n",
            "         weighted avg       0.48      0.69      0.56     10957\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Report\n",
        "print(classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RPXEIrGoKTd",
        "outputId": "5f7347a5-baff-4d9c-ce71-f6f102089489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Original class distribution: [37913  4337  5442  7091]\n",
            "Resampled class distribution: [37913 37913 37913 37913]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Flatten sequences for oversampling\n",
        "X_flat = X_sequences.reshape(len(X_sequences), -1)\n",
        "y_flat = y_sequences  # integer labels, not one-hot\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X_flat, y_flat)\n",
        "\n",
        "# Reshape back into sequence form\n",
        "X_resampled = X_resampled.reshape(-1, sequence_length, X_sequences.shape[2])\n",
        "y_resampled_cat = to_categorical(y_resampled)\n",
        "\n",
        "print(\"Original class distribution:\", np.bincount(y_flat))\n",
        "print(\"Resampled class distribution:\", np.bincount(y_resampled))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAZckRnpoPOW",
        "outputId": "1a9f21c8-e55b-41a7-ee64-c8b530c4683d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m4740/4740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 11ms/step - accuracy: 0.2508 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 2/30\n",
            "\u001b[1m4740/4740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 7ms/step - accuracy: 0.2506 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 3/30\n",
            "\u001b[1m4740/4740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.2478 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 4/30\n",
            "\u001b[1m4740/4740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.2493 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 5/30\n",
            "\u001b[1m4740/4740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.2500 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 6/30\n",
            "\u001b[1m4740/4740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.2528 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 7/30\n",
            "\u001b[1m4740/4740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - accuracy: 0.2500 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 8/30\n",
            "\u001b[1m4740/4740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.2506 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 9/30\n",
            "\u001b[1m4740/4740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - accuracy: 0.2499 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 10/30\n",
            "\u001b[1m4740/4740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.2495 - loss: nan - val_accuracy: 0.6904 - val_loss: nan\n",
            "Epoch 11/30\n",
            "\u001b[1m2459/4740\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.2507 - loss: nan"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_resampled, y_resampled_cat,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Predictions shape:\", y_pred_classes.shape)\n",
        "print(\"True labels shape:\", y_true.shape)"
      ],
      "metadata": {
        "id": "e-kvOWCF2s3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "target_names = [str(c) for c in label_encoder.classes_]\n",
        "\n",
        "report = classification_report(y_true, y_pred_classes, target_names=target_names, zero_division=0)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "tuOa_Tkj2wKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=target_names,\n",
        "            yticklabels=target_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OUze-ZoX2zln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for i, class_name in enumerate(target_names):\n",
        "    idx = y_true == i\n",
        "    class_acc = np.sum(y_pred_classes[idx] == i) / np.sum(idx)\n",
        "    print(f\"Accuracy for {class_name}: {class_acc:.2f}\")"
      ],
      "metadata": {
        "id": "NGxd-RZX257k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='val')\n",
        "plt.title(\"Accuracy over epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.title(\"Loss over epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oo8A7Kim28Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This explains why all predictions appear as boot_delete: the model did not learn the minority classes, leading to:\n",
        "\n",
        "1) Precision/recall = 0 for all non-majority classes.\n",
        "2) SHAP errors, because outputs for other classes are effectively zero and the explanation cannot distribute contributions.\n",
        "\n",
        "Cause:\n",
        "\n",
        "- Extreme class imbalance: boot_delete dominates (~70% of sequences).\n",
        "- Minority classes are too rare: the CNN sees too few examples to learn patterns.\n",
        "- Class weights alone are insufficient; oversampling or sequence-level augmentation is required.\n",
        "\n"
      ],
      "metadata": {
        "id": "PCkGYfcw3fZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Flatten sequences for oversampling\n",
        "X_flat = X_sequences.reshape(len(X_sequences), -1)\n",
        "y_flat = y_sequences\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X_flat, y_flat)\n",
        "\n",
        "# Reshape back into sequences\n",
        "X_resampled = X_resampled.reshape(-1, X_sequences.shape[1], X_sequences.shape[2])\n",
        "y_resampled_cat = to_categorical(y_resampled)\n",
        "\n",
        "print(\"Before oversampling:\", np.bincount(y_flat))\n",
        "print(\"After oversampling:\", np.bincount(y_resampled))"
      ],
      "metadata": {
        "id": "HbI9yoBG3ber"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_resampled, y_resampled_cat,\n",
        "    validation_data=(X_test, y_test),  # keep test set unchanged\n",
        "    epochs=30,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "1atkr8d13ha6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Predictions on test set\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Predictions shape:\", y_pred_classes.shape)\n",
        "print(\"True labels shape:\", y_true.shape)\n",
        "\n",
        "# Classification report\n",
        "\n",
        "target_names = [str(c) for c in label_encoder.classes_]\n",
        "report = classification_report(y_true, y_pred_classes, target_names=target_names, zero_division=0)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(report)\n",
        "\n",
        "# Confusion matrix\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=target_names,\n",
        "            yticklabels=target_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Per-class accuracy\n",
        "\n",
        "print(\"Per-class accuracy:\")\n",
        "for i, class_name in enumerate(target_names):\n",
        "    idx = y_true == i\n",
        "    if np.sum(idx) > 0:\n",
        "        class_acc = np.sum(y_pred_classes[idx] == i) / np.sum(idx)\n",
        "        print(f\"  {class_name}: {class_acc:.2f}\")\n",
        "    else:\n",
        "        print(f\"  {class_name}: No samples in test set\")\n",
        "\n",
        "\n",
        "# Training history plots (if model trained with `history`)\n",
        "if 'history' in globals():\n",
        "    plt.figure(figsize=(12,4))\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='val')\n",
        "    plt.title(\"Model Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label='train')\n",
        "    plt.plot(history.history['val_loss'], label='val')\n",
        "    plt.title(\"Model Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FnD5cZQE33Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuild CNN from scratch\n",
        "input_shape = X_resampled.shape[1:]  # (sequence_length, num_features)\n",
        "\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "x = tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = tf.keras.layers.Dense(y_resampled_cat.shape[1], activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "LFzwJgnj8MD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_resampled, y_resampled_cat,\n",
        "    validation_data=(X_test, y_test),  # test set stays imbalanced\n",
        "    epochs=30,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "8n66LwKN8QUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Any NaNs in X_resampled?\", np.isnan(X_resampled).any())\n",
        "print(\"Any Infs in X_resampled?\", np.isinf(X_resampled).any())"
      ],
      "metadata": {
        "id": "8z79zeWd98Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_resampled = np.nan_to_num(X_resampled, nan=0.0, posinf=1e5, neginf=-1e5)"
      ],
      "metadata": {
        "id": "uqxd2MTi9_6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify\n",
        "print(\"Any NaNs after fix?\", np.isnan(X_resampled).any())"
      ],
      "metadata": {
        "id": "N6aIxInC-UBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Only scale numeric columns\n",
        "scaler = StandardScaler()\n",
        "df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
        "\n",
        "# One-hot categorical columns are already 0/1 → no scaling needed"
      ],
      "metadata": {
        "id": "NkS4O6TJ-B7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Max value:\", X_resampled.max())\n",
        "print(\"Min value:\", X_resampled.min())"
      ],
      "metadata": {
        "id": "rusxWFaL-DyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clip extreme values to [-10, 10] to prevent exploding activations\n",
        "X_resampled = np.clip(X_resampled, -10, 10)"
      ],
      "metadata": {
        "id": "QLGBNEdN-YWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = Adam(learning_rate=1e-4)  # lower LR for stability\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FqJRcet9-aw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Any NaNs in y_resampled_cat?\", np.isnan(y_resampled_cat).any())\n",
        "print(\"Any Infs in y_resampled_cat?\", np.isinf(y_resampled_cat).any())\n",
        "print(\"Min/Max values in y_resampled_cat:\", y_resampled_cat.min(), y_resampled_cat.max())"
      ],
      "metadata": {
        "id": "fBX68CuS-cLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace any remaining NaNs and infinities\n",
        "X_resampled = np.nan_to_num(X_resampled, nan=0.0, posinf=1e5, neginf=-1e5)\n",
        "\n",
        "# Convert to float32\n",
        "X_resampled = X_resampled.astype(np.float32)\n",
        "y_resampled_cat = y_resampled_cat.astype(np.float32)\n",
        "\n",
        "# Clip extreme values for stability\n",
        "X_resampled = np.clip(X_resampled, -10, 10)"
      ],
      "metadata": {
        "id": "ZPFdqSGL-4j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = Adam(learning_rate=1e-4)  # smaller LR prevents exploding gradients"
      ],
      "metadata": {
        "id": "W_CdrLg1_7_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = tf.keras.Input(shape=X_resampled.shape[1:])\n",
        "x = tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same')(inputs)\n",
        "x = tf.keras.layers.Conv1D(16, 3, activation='relu', padding='same')(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(y_resampled_cat.shape[1], activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "l03p624i_9wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_resampled, y_resampled_cat,\n",
        "    validation_data=(X_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "    epochs=30,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "RBRUad7tABJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up validation/test set\n",
        "X_test = np.nan_to_num(X_test, nan=0.0, posinf=1e5, neginf=-1e5)\n",
        "X_test = X_test.astype(np.float32)\n",
        "\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "# Clip extreme values for stability\n",
        "X_test = np.clip(X_test, -10, 10)"
      ],
      "metadata": {
        "id": "8FzQDI6DCoGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain briefly after cleaning X_test\n",
        "history = model.fit(\n",
        "    X_resampled, y_resampled_cat,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=5,            # short run, just to verify val_loss is no longer NaN\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "z8WAulu4CxyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "okAiXydyDl4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"cnn_model.h5\")\n",
        "# Later or in another notebook\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"cnn_model.h5\")"
      ],
      "metadata": {
        "id": "4FLXySakDz5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "1) Training data is heavily oversampled → the model sees many synthetic repetitions of minority classes, making it easy to memorize patterns.\n",
        "2) If features are strongly correlated with labels (e.g., program or pid leaking the operation), the model may use shortcuts for trivial predictions.\n",
        "3) Gap between Train (≈99.8%) and Test (≈99.6%) is very small → suggests possible leakage in preprocessing (scaler/OHE fit on all data).\n",
        "\n",
        "Current issue:\n",
        "RandomOverSampler is fully balancing all classes → risk of overfitting.\n",
        "\n",
        "Better strategies:\n",
        "- imblearn.over_sampling.SMOTE: synthesizes new minority samples instead of duplicating.\n",
        "- Limit oversampling: instead of perfect balance, raise minority classes to ~50% of majority class size.\n",
        "\n"
      ],
      "metadata": {
        "id": "hMbWNXpvFhjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Flatten to 2D for imputer\n",
        "X_train_2d = X_train.reshape(len(X_train), -1)\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X_train_imputed = imputer.fit_transform(X_train_2d)\n",
        "\n",
        "# Reshape back to sequences\n",
        "X_train = X_train_imputed.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])"
      ],
      "metadata": {
        "id": "vWXQshIJGyKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Get class counts\n",
        "unique, counts = np.unique(y_train_int, return_counts=True)\n",
        "class_counts = dict(zip(unique, counts))\n",
        "print(\"Original class counts:\", class_counts)\n",
        "\n",
        "# Define sampling strategy (e.g. minority = 50% of majority)\n",
        "majority_class = max(class_counts, key=class_counts.get)\n",
        "majority_count = class_counts[majority_class]\n",
        "\n",
        "sampling_strategy = {\n",
        "    cls: int(0.5 * majority_count) if count < 0.5 * majority_count else count\n",
        "    for cls, count in class_counts.items()\n",
        "}\n",
        "\n",
        "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
        "\n",
        "X_train_res, y_train_res = smote.fit_resample(\n",
        "    X_train.reshape(len(X_train), -1), y_train_int\n",
        ")\n",
        "\n",
        "# Reshape back to sequences\n",
        "X_train_res = X_train_res.reshape(-1, X_train.shape[1], X_train.shape[2])\n",
        "y_train_res_cat = to_categorical(y_train_res)\n",
        "\n",
        "print(\"Resampled class counts:\", np.bincount(y_train_res))"
      ],
      "metadata": {
        "id": "mr-CcoPgGT-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Baseline accuracy\n",
        "y_pred_base = model.predict(X_test)\n",
        "baseline_acc = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_base, axis=1))\n",
        "\n",
        "importances = []\n",
        "for i in range(X_test.shape[2]):  # loop over features\n",
        "    X_test_perm = X_test.copy()\n",
        "    np.random.shuffle(X_test_perm[:, :, i])  # permute feature\n",
        "    y_pred_perm = model.predict(X_test_perm)\n",
        "    acc_perm = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred_perm, axis=1))\n",
        "    importances.append(baseline_acc - acc_perm)\n",
        "\n",
        "# Rank features by importance\n",
        "feature_names = numeric_features + list(ohe.get_feature_names_out(categorical_features))\n",
        "feat_importances = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Top 15 most important features:\")\n",
        "for name, score in feat_importances[:15]:\n",
        "    print(f\"{name}: {score:.4f}\")"
      ],
      "metadata": {
        "id": "McHDMbU9G_XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations from feature importance\n",
        "\n",
        "\t•\tThe top features are mostly numeric system metrics:\n",
        "\t•\tmem_used_max, load15_mean, cpu_user_max, warning_logs, total_traces, missing_data, etc.\n",
        "\t•\tSome categorical identifiers appear (Hostname_wally123, pid_6.0) but their importance is much smaller.\n",
        "\t•\tMany features have near-zero contribution → keeping them might just add noise and risk overfitting.\n",
        "\n",
        "  What this tells us\n",
        "\n",
        "\t1.\tSystem metrics drive the model — makes sense, the operation affects CPU/memory/load.\n",
        "\t2.\tIdentifiers (hostname/pid) contribute, but minimally → including them is optional.\n",
        "\t•\tKeeping them might help a little, but can also cause overfitting or memorization of host-specific patterns.\n",
        "\t3.\tTop 10–15 features explain most of the predictive power.\n",
        "\t•\tYou can safely drop the rest to simplify the model and improve generalization."
      ],
      "metadata": {
        "id": "GjcpFP6FJi3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_features = [name for name, _ in feat_importances[:15]]\n",
        "\n",
        "# For numeric features\n",
        "X_train_top = X_train_res[:, :, [numeric_features.index(f) for f in top_features if f in numeric_features]]\n",
        "\n",
        "# For categorical features\n",
        "cat_indices = [i for i, f in enumerate(feature_names) if f in top_features and f not in numeric_features]\n",
        "# If using OHE, you can slice columns accordingly\n",
        "# X_train_top_cat = X_train_res[:, :, cat_indices]"
      ],
      "metadata": {
        "id": "BW3ze846JgEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Select top features\n",
        "\n",
        "top_features = [name for name, _ in feat_importances[:15]]\n",
        "\n",
        "# Get indices for numeric features\n",
        "numeric_idx = [numeric_features.index(f) for f in top_features if f in numeric_features]\n",
        "\n",
        "# Get indices for categorical features (OHE columns)\n",
        "cat_idx = [i for i, f in enumerate(ohe.get_feature_names_out(categorical_features)) if f in top_features]\n",
        "\n",
        "# Combine indices\n",
        "top_indices = numeric_idx + [len(numeric_features) + i for i in cat_idx]\n",
        "\n",
        "\n",
        "# Extract top features\n",
        "\n",
        "X_train_top = X_train[:, :, top_indices]\n",
        "X_test_top = X_test[:, :, top_indices]\n",
        "\n",
        "# Impute any remaining NaNs\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X_train_top = imputer.fit_transform(X_train_top.reshape(len(X_train_top), -1))\n",
        "X_test_top = imputer.transform(X_test_top.reshape(len(X_test_top), -1))\n",
        "\n",
        "# Reshape back to sequences\n",
        "seq_len = X_train.shape[1]\n",
        "X_train_top = X_train_top.reshape(-1, seq_len, len(top_indices))\n",
        "X_test_top = X_test_top.reshape(-1, seq_len, len(top_indices))\n",
        "\n",
        "\n",
        "# Re-run SMOTE on training data\n",
        "\n",
        "y_train_int = np.argmax(y_train, axis=1)  # ensure integer labels\n",
        "\n",
        "# Define partial oversampling strategy (50% of majority)\n",
        "unique, counts = np.unique(y_train_int, return_counts=True)\n",
        "class_counts = dict(zip(unique, counts))\n",
        "majority_count = max(class_counts.values())\n",
        "sampling_strategy = {cls: int(0.5*majority_count) if count < 0.5*majority_count else count\n",
        "                     for cls, count in class_counts.items()}\n",
        "\n",
        "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train_top.reshape(len(X_train_top), -1), y_train_int)\n",
        "\n",
        "# Reshape back to sequences\n",
        "X_train_res = X_train_res.reshape(-1, seq_len, len(top_indices))\n",
        "y_train_res_cat = to_categorical(y_train_res)\n",
        "\n",
        "print(\"Resampled class counts:\", np.bincount(y_train_res))\n",
        "\n",
        "\n",
        "# Build smaller CNN\n",
        "\n",
        "input_shape = (seq_len, len(top_indices))\n",
        "inputs = Input(shape=input_shape)\n",
        "x = Conv1D(32, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv1D(16, kernel_size=3, activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "outputs = Dense(y_train_res_cat.shape[1], activation='softmax')(x)\n",
        "\n",
        "model_small = Model(inputs, outputs)\n",
        "model_small.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train model\n",
        "\n",
        "history = model_small.fit(\n",
        "    X_train_res, y_train_res_cat,\n",
        "    validation_data=(X_test_top, y_test),\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "# Evaluate\n",
        "\n",
        "y_pred = np.argmax(model_small.predict(X_test_top), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "oyuKFpu6JlNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_small.save(\"cnn_top15_features.h5\")\n",
        "# Save preprocessing objects\n",
        "import joblib\n",
        "joblib.dump(imputer, \"imputer.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "joblib.dump(ohe, \"ohe.pkl\")\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")"
      ],
      "metadata": {
        "id": "64AMZsPKLTGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: top_features are already selected\n",
        "top_features = [name for name, score in feat_importances[:20]]\n",
        "\n",
        "# Get their column indices\n",
        "top_feature_indices = [feature_names.index(f) for f in top_features]\n"
      ],
      "metadata": {
        "id": "oHgjivBYXk-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Extract only the top features\n",
        "X_top_df = df_encoded[top_features]\n",
        "\n",
        "# Convert to numpy array\n",
        "X_top = X_top_df.to_numpy(dtype=np.float32)\n",
        "\n",
        "# If using sequences (e.g., LSTM/CNN), reshape to (num_samples, seq_len, num_features)\n",
        "# Here seq_len=1 if you don't have sequences\n",
        "X_top = X_top.reshape(len(X_top), 1, len(top_features))\n",
        "\n",
        "# Target\n",
        "y_top = y  # one-hot encoded target\n"
      ],
      "metadata": {
        "id": "6HiNL22WXmuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random 20% of Hostnames for validation\n",
        "hosts = df['Hostname'].unique()\n",
        "val_hosts = np.random.choice(hosts, size=int(0.2*len(hosts)), replace=False)\n",
        "\n",
        "train_idx = ~df['Hostname'].isin(val_hosts)\n",
        "val_idx = df['Hostname'].isin(val_hosts)\n",
        "\n",
        "X_train_top = X_top[train_idx]\n",
        "X_val_top = X_top[val_idx]\n",
        "y_train_top = y_top[train_idx]\n",
        "y_val_top = y_top[val_idx]\n"
      ],
      "metadata": {
        "id": "5z4NF7gGXyOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train_top:\", X_train_top.shape)\n",
        "print(\"X_val_top:\", X_val_top.shape)\n",
        "print(\"y_train_top:\", y_train_top.shape)\n",
        "print(\"y_val_top:\", y_val_top.shape)\n"
      ],
      "metadata": {
        "id": "sytFYe9xX0C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Flatten to 2D\n",
        "X_train_flat = X_train_top.reshape(len(X_train_top), -1)\n",
        "\n",
        "# Impute NaNs using median\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X_train_flat_imputed = imputer.fit_transform(X_train_flat)\n",
        "\n",
        "# Convert back to sequence shape\n",
        "X_train_top_imputed = X_train_flat_imputed.reshape(X_train_top.shape[0], X_train_top.shape[1], X_train_top.shape[2])\n"
      ],
      "metadata": {
        "id": "-Qkq_yhkX-hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Convert y to integer labels\n",
        "y_train_int = np.argmax(y_train_top, axis=1)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X_train_flat_imputed, y_train_int)\n",
        "\n",
        "# Reshape back to sequences\n",
        "X_train_res = X_res.reshape(-1, X_train_top.shape[1], X_train_top.shape[2])\n",
        "y_train_res_cat = to_categorical(y_res)\n",
        "\n",
        "print(\"Resampled class counts:\", np.bincount(y_res))\n"
      ],
      "metadata": {
        "id": "MnSg9oOAYAWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=1, activation='relu', input_shape=(X_train_res.shape[1], X_train_res.shape[2])),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(16, kernel_size=1, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "k1_DrohGYFFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten validation set\n",
        "X_val_flat = X_val_top.reshape(len(X_val_top), -1)\n",
        "\n",
        "# Impute missing values using the same median imputer fitted on training\n",
        "X_val_flat_imputed = imputer.transform(X_val_flat)\n",
        "\n",
        "# Clip extreme values (same as training)\n",
        "X_val_flat_imputed = np.clip(X_val_flat_imputed, -10, 10)\n",
        "\n",
        "# Reshape back to sequence shape\n",
        "X_val_top_imputed = X_val_flat_imputed.reshape(X_val_top.shape[0], X_val_top.shape[1], X_val_top.shape[2])\n"
      ],
      "metadata": {
        "id": "rbx8l2Y4Y__Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train_labels = np.argmax(y_train_top, axis=1)\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train_labels),\n",
        "    y=y_train_labels\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n"
      ],
      "metadata": {
        "id": "rOPJDZYyZB-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Flatten training set\n",
        "X_train_flat = X_train_res.reshape(len(X_train_res), -1)\n",
        "scaler = StandardScaler()\n",
        "X_train_flat_scaled = scaler.fit_transform(X_train_flat)\n",
        "X_train_scaled = X_train_flat_scaled.reshape(X_train_res.shape)\n",
        "\n",
        "# Flatten validation set and scale\n",
        "X_val_flat = X_val_top_imputed.reshape(len(X_val_top_imputed), -1)\n",
        "X_val_flat_scaled = scaler.transform(X_val_flat)\n",
        "X_val_scaled = X_val_flat_scaled.reshape(X_val_top_imputed.shape)\n"
      ],
      "metadata": {
        "id": "fOpXrKlRZEiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=1, activation='relu', input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(16, kernel_size=1, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train_res_cat,\n",
        "    validation_data=(X_val_scaled, y_val_top),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight_dict\n",
        ")\n"
      ],
      "metadata": {
        "id": "xmv0a5VtZPi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "//"
      ],
      "metadata": {
        "id": "M0EK238YbNAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/full_data_long.csv\")\n",
        "\n",
        "# Inspect\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df['operation'].value_counts())\n"
      ],
      "metadata": {
        "id": "7pnWdBexbNo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "vAj931Y8bj-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric columns to impute and scale\n",
        "numeric_features = [\n",
        "    'total_logs',\n",
        "    'error_logs',\n",
        "    'warning_logs',\n",
        "    'info_logs',\n",
        "    'cpu_user_mean',\n",
        "    'cpu_user_max',\n",
        "    'mem_used_mean',\n",
        "    'mem_used_max',\n",
        "    'load1_mean',\n",
        "    'load5_mean',\n",
        "    'load15_mean',\n",
        "    'total_traces',\n",
        "    'missing_data'\n",
        "]\n",
        "\n",
        "# Categorical columns to one-hot encode\n",
        "categorical_features = [\n",
        "    'Hostname',\n",
        "    'user_id',\n",
        "    'program',\n",
        "    'pid'\n",
        "]\n"
      ],
      "metadata": {
        "id": "fYvgNvmzbuSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"num\", StandardScaler(), numeric_features),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "])\n",
        "\n",
        "X = preprocessor.fit_transform(df)\n",
        "y = df['operation']  # target\n"
      ],
      "metadata": {
        "id": "vlD1JaTEbwTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_int = label_encoder.fit_transform(y)  # integer labels\n",
        "y_cat = to_categorical(y_int)           # one-hot encoded for Keras\n"
      ],
      "metadata": {
        "id": "_CSttHQAcD8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to dense array (careful if your dataset is very large)\n",
        "X = X.toarray() if hasattr(X, \"toarray\") else X\n"
      ],
      "metadata": {
        "id": "W1WmS-60cGO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val = X[train_idx], X[val_idx]\n",
        "y_train, y_val = y_cat[train_idx], y_cat[val_idx]\n",
        "y_train_int = y_int[train_idx]\n"
      ],
      "metadata": {
        "id": "MgOVdwzacSfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train_int),\n",
        "    y=y_train_int\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "print(\"Class weights:\", class_weight_dict)\n"
      ],
      "metadata": {
        "id": "dD5UTrv8caWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(y_cat.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "prNsPe5GciC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.isnan(X_train).sum(), np.isinf(X_train).sum())\n",
        "print(np.isnan(X_val).sum(), np.isinf(X_val).sum())\n"
      ],
      "metadata": {
        "id": "di7SI_1Ac0oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = Adam(learning_rate=1e-4)  # lower than default 0.001\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "CZ_Iz2o_dAHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.min(X_train), np.max(X_train))\n"
      ],
      "metadata": {
        "id": "clS4E-AYdDAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Flatten training and validation\n",
        "X_train_flat = X_train_top.reshape(len(X_train_top), -1)\n",
        "X_val_flat = X_val_top.reshape(len(X_val_top), -1)\n",
        "\n",
        "# Impute missing values using median\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_train_flat_imputed = imputer.fit_transform(X_train_flat)\n",
        "X_val_flat_imputed = imputer.transform(X_val_flat)\n",
        "\n",
        "# Check\n",
        "print(np.isnan(X_train_flat_imputed).sum(), np.isnan(X_val_flat_imputed).sum())\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_flat_imputed)\n",
        "X_val_scaled = scaler.transform(X_val_flat_imputed)\n",
        "\n",
        "# Reshape back if using CNN / sequences\n",
        "X_train_scaled = X_train_scaled.reshape(len(X_train_top), 1, X_train_top.shape[2])\n",
        "X_val_scaled = X_val_scaled.reshape(len(X_val_top), 1, X_val_top.shape[2])\n"
      ],
      "metadata": {
        "id": "FnbwwemAdXBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Integer labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_int = label_encoder.fit_transform(y)  # shape (num_samples,)\n",
        "\n",
        "# One-hot labels\n",
        "y_cat = to_categorical(y_int)  # shape (num_samples, num_classes)\n"
      ],
      "metadata": {
        "id": "YQ55AF5-ckHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_cat[train_idx]\n",
        "y_val = y_cat[val_idx]\n",
        "\n",
        "y_train_int = y_int[train_idx]  # needed for class weights\n"
      ],
      "metadata": {
        "id": "RaAukWtZdhLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train_int),\n",
        "    y=y_train_int\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "print(\"Class weights:\", class_weight_dict)\n"
      ],
      "metadata": {
        "id": "VdNxNNHUdjRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=1, activation='relu', input_shape=(1, X_train_scaled.shape[2])),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(16, kernel_size=1, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_cat.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "KAv5xD_XdjMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "//"
      ],
      "metadata": {
        "id": "jfaOwUFseCUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/content/full_data_long.csv\")\n",
        "\n",
        "# Define features\n",
        "numeric_features = [\n",
        "    'total_logs', 'error_logs', 'warning_logs', 'info_logs',\n",
        "    'cpu_user_mean', 'cpu_user_max', 'mem_used_mean', 'mem_used_max',\n",
        "    'load1_mean', 'load5_mean', 'load15_mean', 'total_traces', 'pid'\n",
        "]\n",
        "\n",
        "categorical_features = [\n",
        "    'Hostname', 'user_id', 'program'\n",
        "]\n",
        "\n",
        "# Add missing_data column\n",
        "df['missing_data'] = df[numeric_features].isna().sum(axis=1)\n",
        "\n",
        "# Update numeric_features to include missing_data\n",
        "numeric_features.append('missing_data')\n",
        "\n",
        "# Target\n",
        "y = df['operation']\n",
        "\n",
        "# Encode target\n",
        "label_encoder = LabelEncoder()\n",
        "y_int = label_encoder.fit_transform(y)\n",
        "\n",
        "# One-hot encode target for Keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_cat = to_categorical(y_int)\n",
        "\n",
        "# Preprocessor for features\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"num\", StandardScaler(), numeric_features),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "])\n",
        "\n",
        "# Fit and transform features\n",
        "X = preprocessor.fit_transform(df)\n",
        "\n",
        "# Convert to dense array if sparse\n",
        "if hasattr(X, \"toarray\"):\n",
        "    X = X.toarray()\n",
        "\n",
        "# Split by Hostname to avoid leakage\n",
        "hosts = df['Hostname'].unique()\n",
        "val_hosts = np.random.choice(hosts, size=int(0.2 * len(hosts)), replace=False)\n",
        "\n",
        "train_idx = ~df['Hostname'].isin(val_hosts)\n",
        "val_idx = df['Hostname'].isin(val_hosts)\n",
        "\n",
        "X_train = X[train_idx]\n",
        "X_val = X[val_idx]\n",
        "y_train = y_cat[train_idx]\n",
        "y_val = y_cat[val_idx]\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape)\n",
        "print(\"y_train:\", y_train.shape, \"y_val:\", y_val.shape)\n",
        "\n",
        "# Check for NaNs / infs\n",
        "print(\"NaNs in X_train:\", np.isnan(X_train).sum())\n",
        "print(\"NaNs in X_val:\", np.isnan(X_val).sum())\n",
        "print(\"Infs in X_train:\", np.isinf(X_train).sum())\n",
        "print(\"Infs in X_val:\", np.isinf(X_val).sum())\n",
        "\n",
        "# Impute missing values if any (numeric columns)\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_val = imputer.transform(X_val)\n",
        "\n",
        "# Scale numeric features (optional, already scaled in ColumnTransformer, but safe)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Now X_train, X_val, y_train, y_val are clean and ready for modeling\n"
      ],
      "metadata": {
        "id": "5pdGgWVjeC91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Convert y_train back to integer labels\n",
        "y_train_int = np.argmax(y_train, axis=1)\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train_int),\n",
        "    y=y_train_int\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "print(\"Class weights:\", class_weight_dict)\n"
      ],
      "metadata": {
        "id": "Svu0T1Cmeddt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Only on training set\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_res, y_train_res_int = smote.fit_resample(X_train, y_train_int)\n",
        "\n",
        "# One-hot encode labels again for Keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train_res = to_categorical(y_train_res_int)\n"
      ],
      "metadata": {
        "id": "quOFLKcyeic7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_dim = X_train_res.shape[1]\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train_res.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "KuJ0OjUIekuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_processed_dense = X_processed.toarray()  # convert sparse to dense\n",
        "\n",
        "X_train = X_processed_dense[train_mask]\n",
        "X_val   = X_processed_dense[val_mask]\n",
        "\n",
        "y_train = y_onehot[train_mask]\n",
        "y_val   = y_onehot[val_mask]\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n"
      ],
      "metadata": {
        "id": "w9b7IbT6fYDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If X_processed is a Series, convert it\n",
        "X_processed = np.array(X_processed)\n"
      ],
      "metadata": {
        "id": "BfI_T6pEfdVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = ~df_clean['Hostname'].isin(val_hosts).to_numpy()\n",
        "val_mask   = df_clean['Hostname'].isin(val_hosts).to_numpy()\n"
      ],
      "metadata": {
        "id": "lNCDntvzfwcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/content/full_data_long.csv\")\n",
        "\n",
        "# Define features and target\n",
        "target_col = 'operation'\n",
        "categorical_features = ['user_id', 'program', 'pid']  # example, adjust as needed\n",
        "numeric_features = [c for c in df.columns if c not in categorical_features + [target_col, 'Hostname', 'bin_time']]\n",
        "\n",
        "# Clean any NaNs in numeric_features for sanity check\n",
        "df[numeric_features] = df[numeric_features].fillna(df[numeric_features].median())\n",
        "\n",
        "# Split by Hostname to avoid leakage\n",
        "hosts = df['Hostname'].unique()\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(hosts)\n",
        "n_val = max(1, int(0.2 * len(hosts)))  # ensure at least 1 hostname\n",
        "val_hosts = hosts[:n_val]\n",
        "train_hosts = hosts[n_val:]\n",
        "\n",
        "train_mask = df['Hostname'].isin(train_hosts)\n",
        "val_mask   = df['Hostname'].isin(val_hosts)\n",
        "\n",
        "df_train = df[train_mask]\n",
        "df_val   = df[val_mask]\n",
        "\n",
        "print(\"Training samples:\", len(df_train))\n",
        "print(\"Validation samples:\", len(df_val))\n",
        "\n",
        "# Preprocessing: Impute numeric, encode categorical\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', SimpleImputer(strategy='median'), numeric_features),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
        "])\n",
        "\n",
        "# Fit on training, transform both train and validation\n",
        "X_train = preprocessor.fit_transform(df_train)\n",
        "X_val   = preprocessor.transform(df_val)\n",
        "\n",
        "# Scale numeric features (all columns after OneHotEncoder)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val   = scaler.transform(X_val)\n",
        "\n",
        "# Prepare target safely\n",
        "\n",
        "# Convert everything to string first\n",
        "y_train_labels = df_train[target_col].astype(str).values\n",
        "y_val_labels   = df_val[target_col].astype(str).values\n",
        "\n",
        "# Create integer encoding\n",
        "unique_labels = np.unique(y_train_labels)\n",
        "label_encoder = {label: i for i, label in enumerate(unique_labels)}\n",
        "\n",
        "y_train_int = np.array([label_encoder[l] for l in y_train_labels])\n",
        "y_val_int   = np.array([label_encoder[l] for l in y_val_labels])\n",
        "\n",
        "# One-hot encode\n",
        "y_train = to_categorical(y_train_int)\n",
        "y_val   = to_categorical(y_val_int)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights_values = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train_int),\n",
        "    y=y_train_int\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights_values))\n",
        "print(\"Class weights:\", class_weight_dict)\n",
        "\n",
        "\n",
        "# Reshape for CNN if needed: (samples, 1, features)\n",
        "X_train = X_train.reshape(len(X_train), 1, X_train.shape[1])\n",
        "X_val   = X_val.reshape(len(X_val), 1, X_val.shape[1])\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n"
      ],
      "metadata": {
        "id": "lVpcoH65g0JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "num_features = X_train.shape[2]\n",
        "num_classes  = y_train.shape[1]\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=1, activation='relu', input_shape=(1, num_features)),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(16, kernel_size=1, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "QX1QmUerhKC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = y_train.shape[1]  # <- 3 in your case\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=1, activation='relu', input_shape=(1, X_train.shape[2])),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(16, kernel_size=1, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation='softmax')  # <- match y_train\n",
        "])\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ju5eYfGghOBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Combine all labels to find unique classes\n",
        "all_labels = np.unique(np.concatenate([y_train_labels, y_val_labels]))\n",
        "\n",
        "# Map labels to consecutive integers\n",
        "label_to_int = {label: i for i, label in enumerate(all_labels)}\n",
        "\n",
        "y_train_int = np.array([label_to_int[l] for l in y_train_labels])\n",
        "y_val_int   = np.array([label_to_int[l] for l in y_val_labels])\n",
        "\n",
        "# One-hot encode\n",
        "num_classes = len(all_labels)\n",
        "y_train = to_categorical(y_train_int, num_classes=num_classes)\n",
        "y_val   = to_categorical(y_val_int, num_classes=num_classes)\n",
        "\n",
        "print(\"num_classes:\", num_classes)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n"
      ],
      "metadata": {
        "id": "PFAcLnbriNz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=1, activation='relu', input_shape=(1, X_train.shape[2])),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(16, kernel_size=1, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation='softmax')  # now matches y_train\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "glrBvERwiQSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight_dict,  # optional, helps with class imbalance\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "8pjovJHnif1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\"Validation accuracy: {val_acc:.4f}, loss: {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "P6gs2MK5mmxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(X_val)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "y_true = np.argmax(y_val, axis=1)\n"
      ],
      "metadata": {
        "id": "CUGqVxpPmqb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "present_classes = np.unique(np.concatenate([y_true, y_pred]))\n",
        "print(classification_report(y_true, y_pred, labels=present_classes, target_names=[all_labels[i] for i in present_classes]))\n",
        "print(confusion_matrix(y_true, y_pred, labels=present_classes))\n"
      ],
      "metadata": {
        "id": "gVvbiVPYms33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing target\n",
        "df = df.dropna(subset=[target_col])\n",
        "\n",
        "# Convert all target values to string (avoids mixed types)\n",
        "df[target_col] = df[target_col].astype(str)\n",
        "\n",
        "# Split train/validation by Hostname\n",
        "hosts = df['Hostname'].unique()\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(hosts)\n",
        "n_val = max(1, int(0.2 * len(hosts)))\n",
        "val_hosts = hosts[:n_val]\n",
        "train_hosts = hosts[n_val:]\n",
        "\n",
        "train_mask = df['Hostname'].isin(train_hosts)\n",
        "val_mask   = df['Hostname'].isin(val_hosts)\n",
        "\n",
        "df_train = df[train_mask]\n",
        "df_val   = df[val_mask]\n",
        "\n",
        "# Extract target labels safely\n",
        "y_train_labels = df_train[target_col].values\n",
        "y_val_labels   = df_val[target_col].values\n",
        "\n",
        "# Map to integer IDs\n",
        "all_labels = np.unique(np.concatenate([y_train_labels, y_val_labels]))\n",
        "label_to_int = {label: i for i, label in enumerate(all_labels)}\n",
        "\n",
        "y_train_int = np.array([label_to_int[l] for l in y_train_labels])\n",
        "y_val_int   = np.array([label_to_int[l] for l in y_val_labels])\n",
        "\n",
        "# One-hot encode\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "num_classes = len(all_labels)\n",
        "y_train = to_categorical(y_train_int, num_classes=num_classes)\n",
        "y_val   = to_categorical(y_val_int, num_classes=num_classes)\n",
        "\n",
        "print(\"All labels:\", all_labels)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n"
      ],
      "metadata": {
        "id": "k-CjiUofoRCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define categorical and numeric features\n",
        "categorical_features = ['user_id', 'program', 'pid']  # adjust if needed\n",
        "numeric_features = [c for c in df.columns if c not in categorical_features + [target_col, 'Hostname', 'bin_time']]\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', SimpleImputer(strategy='median'), numeric_features),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
        "])\n",
        "\n",
        "# Fit on train, transform train and val\n",
        "X_train = preprocessor.fit_transform(df_train)\n",
        "X_val   = preprocessor.transform(df_val)\n",
        "\n",
        "# Scale all features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val   = scaler.transform(X_val)\n",
        "\n",
        "# Reshape for CNN (samples, 1, features)\n",
        "X_train = X_train.reshape(len(X_train), 1, X_train.shape[1])\n",
        "X_val   = X_val.reshape(len(X_val), 1, X_val.shape[1])\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n"
      ],
      "metadata": {
        "id": "W94TFopdoiH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y_train_labels_int = np.argmax(y_train, axis=1)\n",
        "class_weights_values = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train_labels_int),\n",
        "    y=y_train_labels_int\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights_values))\n",
        "print(\"Class weights:\", class_weight_dict)\n"
      ],
      "metadata": {
        "id": "5thBU0d9okRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=1, activation='relu', input_shape=(1, X_train.shape[2])),\n",
        "    BatchNormalization(),\n",
        "    Conv1D(16, kernel_size=1, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "62Mop5NGont_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=2\n",
        ")\n"
      ],
      "metadata": {
        "id": "cmm7OaLJopyy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0c0uJdUG1xcCrfnwuwn0c",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}